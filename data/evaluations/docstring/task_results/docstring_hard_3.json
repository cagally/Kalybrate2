{
  "task_id": "docstring_hard_3",
  "prompt": "I'm documenting a set of related PyTorch functions: the main function, its in-place variant, and an alias. I need proper documentation for all three that follows PyTorch conventions. The functions are: def normalize_tensor(input, p=2, dim=1, eps=1e-12), def normalize_tensor_(input, p=2, dim=1, eps=1e-12) (in-place), and def norm_tensor(input, p=2, dim=1, eps=1e-12) (alias). Each needs appropriate documentation with cross-references between them.",
  "difficulty": "hard",
  "model": "claude-3-5-haiku-20241022",
  "response": "I'll help you create a well-documented set of functions following PyTorch docstring conventions. I'll write the code with comprehensive docstrings that cross-reference each other.\n\n```python\nimport torch\nfrom torch import Tensor\n\ndef normalize_tensor(input: Tensor, p: float = 2, dim: int = 1, eps: float = 1e-12) -> Tensor:\n    r\"\"\"Normalizes a tensor along a specified dimension using the p-norm.\n\n    Computes a tensor where each slice along the specified dimension is normalized \n    by dividing by the p-norm of that slice, with a small epsilon for numerical stability.\n\n    .. math::\n        \\text{output} = \\frac{\\text{input}}{\\max(\\text{norm}(x, p), \\epsilon)}\n\n    Args:\n        input (Tensor): Input tensor to be normalized\n        p (float, optional): Order of the norm (p-norm). Default: 2\n        dim (int, optional): Dimension along which to compute the norm. Default: 1\n        eps (float, optional): Small value to avoid division by zero. Default: 1e-12\n\n    Returns:\n        Tensor: Normalized tensor with the same shape as input\n\n    Examples::\n        >>> x = torch.randn(3, 4)\n        >>> normalized = torch.normalize_tensor(x)\n        >>> normalized.shape == x.shape\n        True\n        >>> torch.allclose(normalized.norm(p=2, dim=1), torch.ones(3), atol=1e-7)\n        True\n\n    See Also:\n        - :meth:`~normalize_tensor_` for the in-place version\n        - :func:`torch.norm_tensor` for an alias of this function\n    \"\"\"\n    # Compute the norm along the specified dimension\n    norm = input.norm(p=p, dim=dim, keepdim=True)\n    # Normalize with epsilon to avoid division by zero\n    return input / (norm.clamp(min=eps))\n\ndef normalize_tensor_(input: Tensor, p: float = 2, dim: int = 1, eps: float = 1e-12) -> Tensor:\n    r\"\"\"In-place version of :func:`torch.normalize_tensor`.\n\n    Normalizes a tensor along a specified dimension using the p-norm, modifying the \n    input tensor in-place.\n\n    Args:\n        input (Tensor): Input tensor to be normalized in-place\n        p (float, optional): Order of the norm (p-norm). Default: 2\n        dim (int, optional): Dimension along which to compute the norm. Default: 1\n        eps (float, optional): Small value to avoid division by zero. Default: 1e-12\n\n    Returns:\n        Tensor: The input tensor after in-place normalization\n\n    Examples::\n        >>> x = torch.randn(3, 4)\n        >>> torch.normalize_tensor_(x)\n        >>> x.norm(p=2, dim=1).allclose(torch.ones(3), atol=1e-7)\n        True\n\n    See Also:\n        - :func:`torch.normalize_tensor` for the out-of-place version\n        - :func:`torch.norm_tensor` for an alias of this function\n    \"\"\"\n    # Compute the norm along the specified dimension\n    norm = input.norm(p=p, dim=dim, keepdim=True)\n    # In-place division with clamped norm to avoid division by zero\n    input.div_(norm.clamp(min=eps))\n    return input\n\ndef norm_tensor(input: Tensor, p: float = 2, dim: int = 1, eps: float = 1e-12) -> Tensor:\n    r\"\"\"Alias for :func:`torch.normalize_tensor`.\n\n    This function is an alias of :func:`normalize_tensor` and provides \n    the same functionality of normalizing a tensor along a specified dimension.\n\n    Args:\n        input (Tensor): Input tensor to be normalized\n        p (float, optional): Order of the norm (p-norm). Default: 2\n        dim (int, optional): Dimension along which to compute the norm. Default: 1\n        eps (float, optional): Small value to avoid division by zero. Default: 1e-12\n\n    Returns:\n        Tensor: Normalized tensor with the same shape as input\n\n    Examples::\n        >>> x = torch.randn(3, 4)\n        >>> normalized = torch.norm_tensor(x)\n        >>> normalized.shape == x.shape\n        True\n\n    See Also:\n        - :func:`torch.normalize_tensor` for the primary implementation\n        - :meth:`~normalize_tensor_` for the in-place version\n    \"\"\"\n    return normalize_tensor(input, p=p, dim=dim, eps=eps)\n\n# Add the functions to torch namespace (simulating PyTorch's function registration)\ntorch.normalize_tensor = normalize_tensor\ntorch.normalize_tensor_ = normalize_tensor_\ntorch.norm_tensor = norm_tensor\n```\n\nThis implementation follows PyTorch docstring conventions by:\n\n1. Using raw strings (`r\"\"\"`) for docstrings\n2. Providing a clear description of each function\n3. Including mathematical notation where appropriate\n4. Documenting all parameters with types and default values\n5. Providing meaningful examples\n6. Using cross-references with `:func:` and `:meth:` roles\n7. Adding \"See Also\" sections to link related functions\n8. Maintaining consistent function signatures\n9. Adding type hints for better clarity\n\nThe implementation includes:\n- The main `normalize_tensor` function\n- Its in-place variant `normalize_tensor_`\n- An alias `norm_tensor`\n\nThe functions simulate how PyTorch might add these to its namespace, with cross-references and consistent behavior. The docstrings provide clear documentation about the function's purpose, parameters, and usage.\n\nYou can test these functions like this:\n\n```python\n# Example usage\nx = torch.randn(3, 4)\nnormalized = torch.normalize_tensor(x)\ntorch.normalize_tensor_(x)  # in-place\naliased = torch.norm_tensor(x)\n```\n\nThe docstrings provide comprehensive information while following PyTorch's documentation style.",
  "criteria_results": {
    "code_extracted": true,
    "has_docstrings": true
  },
  "verification_notes": {
    "code_extracted": "verified",
    "has_docstrings": "verified"
  },
  "verification_level": "full",
  "verified_criteria": {
    "passed": 2,
    "total": 2
  },
  "passed": true,
  "tokens": {
    "input": 3181,
    "output": 1466,
    "total": 4647
  },
  "execution_time": 21.531173944473267,
  "error": null,
  "timestamp": "2026-01-01T18:42:48.557907"
}