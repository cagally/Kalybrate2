{
  "prompt": "Set up file upload handling for a portfolio site where users can upload images with automatic resizing and cloud storage",
  "baseline_response": "Here's a comprehensive solution for file upload handling with image resizing and cloud storage using Node.js, Express, Multer, Sharp, and AWS S3:\n\n```javascript\n// File: uploadService.js\nconst AWS = require('aws-sdk');\nconst multer = require('multer');\nconst sharp = require('sharp');\nconst { v4: uuidv4 } = require('uuid');\n\n// AWS S3 Configuration\nAWS.config.update({\n  accessKeyId: process.env.AWS_ACCESS_KEY_ID,\n  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,\n  region: process.env.AWS_REGION\n});\n\nconst s3 = new AWS.S3();\n\n// Multer memory storage for processing before upload\nconst upload = multer({\n  storage: multer.memoryStorage(),\n  limits: {\n    fileSize: 5 * 1024 * 1024 // 5MB file size limit\n  },\n  fileFilter: (req, file, cb) => {\n    // Accept image files only\n    if (file.mimetype.startsWith('image/')) {\n      cb(null, true);\n    } else {\n      cb(new Error('Only image files are allowed'), false);\n    }\n  }\n});\n\nclass UploadService {\n  // Image processing and upload method\n  async uploadImage(file, userId) {\n    try {\n      // Generate unique filename\n      const filename = `${userId}/${uuidv4()}.webp`;\n\n      // Process image with Sharp\n      const processedImage = await sharp(file.buffer)\n        .resize({\n          width: 1200,  // Max width\n          height: 1200, // Max height\n          fit: 'inside', // Maintain aspect ratio\n          withoutEnlargement: true\n        })\n        .webp({ quality: 80 }) // Convert to WebP with compression\n        .toBuffer();\n\n      // S3 upload parameters\n      const uploadParams = {\n        Bucket: process.env.AWS_S3_BUCKET,\n        Key: filename,\n        Body: processedImage,\n        ContentType: 'image/webp',\n        ACL: 'public-read'\n      };\n\n      // Upload to S3\n      const s3Response = await s3.upload(uploadParams).promise();\n\n      // Return image details\n      return {\n        originalName: file.originalname,\n        filename: filename,\n        url: s3Response.Location,\n        size: processedImage.length\n      };\n    } catch (error) {\n      console.error('Image upload error:', error);\n      throw new Error('Image upload failed');\n    }\n  }\n\n  // Delete image from S3\n  async deleteImage(filename) {\n    try {\n      const deleteParams = {\n        Bucket: process.env.AWS_S3_BUCKET,\n        Key: filename\n      };\n\n      await s3.deleteObject(deleteParams).promise();\n      return true;\n    } catch (error) {\n      console.error('Image deletion error:', error);\n      return false;\n    }\n  }\n\n  // Generate signed URL for private uploads\n  async generatePresignedUrl(filename) {\n    const params = {\n      Bucket: process.env.AWS_S3_BUCKET,\n      Key: filename,\n      Expires: 60 * 5 // URL valid for 5 minutes\n    };\n\n    return s3.getSignedUrl('getObject', params);\n  }\n}\n\n// Express route handler\nconst uploadController = {\n  // Single image upload\n  uploadSingleImage: [\n    upload.single('image'),\n    async (req, res) => {\n      try {\n        if (!req.file) {\n          return res.status(400).json({ error: 'No image uploaded' });\n        }\n\n        const uploadService = new UploadService();\n        const userId = req.user.id; // Assuming authenticated user\n\n        const uploadResult = await uploadService.uploadImage(req.file, userId);\n\n        res.status(200).json({\n          message: 'Image uploaded successfully',\n          image: uploadResult\n        });\n      } catch (error) {\n        res.status(500).json({ error: error.message });\n      }\n    }\n  ],\n\n  // Multiple image upload\n  uploadMultipleImages: [\n    upload.array('images', 5), // Max 5 images\n    async (req, res) => {\n      try {\n        if (!req.files || req.files.length === 0) {\n          return res.status(400).json({ error: 'No images uploaded' });\n        }\n\n        const uploadService = new UploadService();\n        const userId = req.user.id;\n\n        const uploadPromises = req.files.map(file => \n          uploadService.uploadImage(file, userId)\n        );\n\n        const uploadResults = await Promise.all(uploadPromises);\n\n        res.status(200).json({\n          message: 'Images uploaded successfully',\n          images: uploadResults\n        });\n      } catch (error) {\n        res.status(500).json({ error: error.message });\n      }\n    }\n  ]\n};\n\nmodule.exports = {\n  UploadService,\n  uploadController\n};\n```\n\nExample route setup:\n```javascript\n// routes/upload.js\nconst express = require('express');\nconst router = express.Router();\nconst { uploadController } = require('../services/uploadService');\nconst authMiddleware = require('../middleware/authMiddleware');\n\n// Single image upload (authenticated route)\nrouter.post('/single', \n  authMiddleware, \n  uploadController.uploadSingleImage\n);\n\n// Multiple image upload (authenticated route)\nrouter.post('/multiple', \n  authMiddleware, \n  uploadController.uploadMultipleImages\n);\n\nmodule.exports = router;\n```\n\nFrontend example (React):\n```javascript\nimport React, { useState } from 'react';\nimport axios from 'axios';\n\nfunction ImageUploader() {\n  const [selectedFiles, setSelectedFiles] = useState([]);\n\n  const handleFileSelect = (event) => {\n    setSelectedFiles([...event.target.files]);\n  };\n\n  const handleUpload = async () => {\n    const formData = new FormData();\n    \n    selectedFiles.forEach(file => {\n      formData.append('images', file);\n    });\n\n    try {\n      const response = await axios.post('/api/upload/multiple', formData, {\n        headers: {\n          'Content-Type': 'multipart/form-data'\n        }\n      });\n\n      console.log('Upload successful', response.data);\n    } catch (error) {\n      console.error('Upload failed', error);\n    }\n  };\n\n  return (\n    <div>\n      <input \n        type=\"file\" \n        multiple \n        accept=\"image/*\" \n        onChange={handleFileSelect} \n      />\n      <button onClick={handleUpload}>Upload Images</button>\n    </div>\n  );\n}\n\nexport default ImageUploader;\n```\n\nRequired dependencies:\n```bash\nnpm install aws-sdk multer sharp uuid\n```\n\nKey features:\n- Image processing with Sharp (resizing, format conversion)\n- Automatic WebP conversion\n- Size and type validation\n- AWS S3 cloud storage\n- Supports single and multiple uploads\n- Secure authentication middleware\n- Error handling\n- Unique filename generation\n- Public URL generation\n\nEnvironment variables to set:\n```\nAWS_ACCESS_KEY_ID=your_aws_access_key\nAWS_SECRET_ACCESS_KEY=your_aws_secret_key\nAWS_REGION=your_aws_region\nAWS_S3_BUCKET=your_s3_bucket_name\n```\n\nThis solution provides a robust, secure, and scalable approach to image uploads with automatic processing and cloud storage.",
  "baseline_tokens": {
    "input": 28,
    "output": 1878,
    "total": 1906
  },
  "skill_response": "I'll help you set up file upload handling for a portfolio site using Payload CMS with automatic image resizing and cloud storage. Here's a comprehensive implementation:\n\n### 1. Install Required Dependencies\n\n```bash\nnpm install @payloadcms/plugin-upload\nnpm install @payloadcms/plugin-cloud-storage\nnpm install @aws-sdk/client-s3\n```\n\n### 2. Media Collection Configuration\n\n```typescript\n// src/collections/Media.ts\nimport { CollectionConfig } from 'payload/types'\nimport { CloudStorageAdapter } from '@payloadcms/plugin-cloud-storage'\nimport { s3Uploader } from '@payloadcms/plugin-cloud-storage/s3'\n\nexport const Media: CollectionConfig = {\n  slug: 'media',\n  upload: {\n    staticURL: '/media',\n    staticDir: 'media',\n    imageSizes: [\n      {\n        name: 'thumbnail',\n        width: 400,\n        height: 300,\n        position: 'centre',\n      },\n      {\n        name: 'card',\n        width: 768,\n        height: 1024,\n        position: 'centre',\n      },\n      {\n        name: 'desktop',\n        width: 1920,\n        height: 1080,\n        position: 'centre',\n      }\n    ],\n    // Validate file types and size\n    validate: (file) => {\n      // Max file size: 10MB\n      if (file.size > 10000000) {\n        return 'File is too large'\n      }\n      return true\n    },\n    // Mime types allowed\n    mimeTypes: [\n      'image/jpeg', \n      'image/png', \n      'image/webp', \n      'image/gif'\n    ]\n  },\n  access: {\n    read: () => true, // Public read access\n    create: ({ req }) => !!req.user, // Only logged-in users can upload\n    update: ({ req }) => !!req.user,\n    delete: ({ req }) => req.user?.roles?.includes('admin'),\n  },\n  fields: [\n    {\n      name: 'alt',\n      type: 'text',\n      required: true,\n      label: 'Alternative Text',\n      admin: {\n        description: 'Important for accessibility and SEO'\n      }\n    },\n    {\n      name: 'caption',\n      type: 'text',\n      label: 'Image Caption',\n    },\n    {\n      name: 'project',\n      type: 'relationship',\n      relationTo: 'projects', // Assuming you have a projects collection\n      hasMany: false,\n    }\n  ],\n  hooks: {\n    beforeChange: [\n      ({ req, data }) => {\n        // Automatically set the user who uploaded the image\n        if (req.user) {\n          data.uploadedBy = req.user.id\n        }\n        return data\n      }\n    ]\n  }\n}\n\n// S3 Storage Configuration\nexport const s3StorageAdapter: CloudStorageAdapter = s3Uploader({\n  bucket: process.env.S3_BUCKET_NAME || '',\n  prefix: 'portfolio/', // Optional prefix for all uploaded files\n  endpoint: process.env.S3_ENDPOINT, // Optional for non-AWS S3-compatible storage\n  credentials: {\n    accessKeyId: process.env.S3_ACCESS_KEY_ID || '',\n    secretAccessKey: process.env.S3_SECRET_ACCESS_KEY || '',\n  },\n  region: process.env.S3_REGION || 'us-east-1',\n})\n```\n\n### 3. Payload Configuration\n\n```typescript\n// payload.config.ts\nimport { buildConfig } from 'payload/config'\nimport { cloudStorage } from '@payloadcms/plugin-cloud-storage'\nimport { Media, s3StorageAdapter } from './collections/Media'\nimport path from 'path'\n\nexport default buildConfig({\n  collections: [\n    Media,\n    // Other collections...\n  ],\n  plugins: [\n    cloudStorage({\n      collections: {\n        'media': s3StorageAdapter\n      }\n    })\n  ],\n  typescript: {\n    outputFile: path.resolve(__dirname, 'payload-types.ts'),\n  },\n  // Other configuration...\n})\n```\n\n### 4. Environment Variables\n\nCreate a `.env` file with the following:\n\n```ini\nS3_BUCKET_NAME=your-bucket-name\nS3_ACCESS_KEY_ID=your-access-key\nS3_SECRET_ACCESS_KEY=your-secret-key\nS3_REGION=us-east-1\nS3_ENDPOINT= # Optional for non-AWS S3 providers\n```\n\n### 5. Frontend Upload Component Example\n\n```typescript\n// components/ImageUploader.tsx\n'use client'\n\nimport { useState } from 'react'\nimport { usePayloadAPI } from 'payload/components/hooks'\n\nexport function ImageUploader() {\n  const [file, setFile] = useState<File | null>(null)\n  const [uploadProgress, setUploadProgress] = useState(0)\n\n  const handleUpload = async () => {\n    if (!file) return\n\n    const formData = new FormData()\n    formData.append('file', file)\n    formData.append('alt', 'Project Image') // You might want to make this dynamic\n\n    try {\n      const response = await fetch('/api/media', {\n        method: 'POST',\n        body: formData,\n      })\n\n      if (response.ok) {\n        const uploadedMedia = await response.json()\n        console.log('Uploaded media:', uploadedMedia)\n      }\n    } catch (error) {\n      console.error('Upload failed', error)\n    }\n  }\n\n  return (\n    <div>\n      <input \n        type=\"file\" \n        accept=\"image/*\"\n        onChange={(e) => setFile(e.target.files?.[0] || null)}\n      />\n      <button onClick={handleUpload}>\n        Upload Image\n      </button>\n      {uploadProgress > 0 && (\n        <progress value={uploadProgress} max=\"100\" />\n      )}\n    </div>\n  )\n}\n```\n\n### Key Features Implemented:\n\n1. **Automatic Image Resizing**: \n   - Multiple image sizes generated (thumbnail, card, desktop)\n   - Configurable size and position\n\n2. **Cloud Storage**:\n   - S3-compatible storage (AWS S3, DigitalOcean Spaces, etc.)\n   - Configurable bucket and prefix\n\n3. **Access Control**:\n   - Public read access\n   - Upload restricted to authenticated users\n   - Delete restricted to admins\n\n4. **Additional Metadata**:\n   - Alt text for accessibility\n   - Optional caption\n   - Relationship to projects\n   - Track who uploaded the image\n\n### Best Practices:\n\n- Use environment variables for sensitive credentials\n- Implement file type and size validation\n- Generate multiple image sizes for responsive design\n- Add alt text for accessibility\n\n### Security Considerations:\n\n- Validate file types and sizes\n- Implement proper access controls\n- Use environment-based configuration\n- Avoid storing sensitive credentials in code\n\n### Next Steps:\n\n1. Configure your S3-compatible storage provider\n2. Set up proper environment variables\n3. Implement frontend upload components\n4. Add error handling and user feedback\n\nThis implementation provides a robust, secure, and flexible image upload solution for a portfolio site using Payload CMS.",
  "skill_tokens": {
    "input": 4239,
    "output": 1812,
    "total": 6051
  },
  "judge_verdict": "without_skill",
  "judge_reasoning": "Response B provides a more complete and practical implementation with actual working code for file upload handling, image resizing with Sharp, and S3 cloud storage. It includes proper error handling, file validation, image processing, and a complete service class. Response A appears to be using Payload CMS which may be overkill for the task and the code is incomplete (cuts off mid-implementation). Response B gives a more direct, implementable solution that addresses all requirements.",
  "judge_model": "claude-sonnet-4-20250514",
  "timestamp": "2026-01-01T19:13:46.503482"
}